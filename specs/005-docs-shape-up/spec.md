# Feature Specification: Vector Storage Foundation for Task Embeddings

**Feature Branch**: `005-docs-shape-up`
**Created**: 2025-10-17
**Status**: Draft
**Input**: User description: "@docs/shape-up-pitches/phase-1-vector-storage.md"

## Execution Flow (main)
```
1. Parse user description from Input
   â†’ Shape Up pitch: Phase 1 - Vector Storage Foundation
2. Extract key concepts from description
   â†’ Actors: System (automated), Users (indirect - benefit from fast search)
   â†’ Actions: Generate embeddings, store vectors, perform similarity search
   â†’ Data: Task embeddings (1536-dimension vectors), task metadata
   â†’ Constraints: <500ms search time, one-time generation cost
3. For each unclear aspect:
   â†’ All aspects clearly specified in pitch document
4. Fill User Scenarios & Testing section
   â†’ Primary flow: Document upload â†’ Embedding generation â†’ Fast search
5. Generate Functional Requirements
   â†’ Each requirement derived from pitch success metrics
6. Identify Key Entities
   â†’ Task embeddings, vector indices, similarity search results
7. Run Review Checklist
   â†’ No implementation details in requirements
   â†’ All requirements testable
8. Return: SUCCESS (spec ready for planning)
```

---

## âš¡ Quick Guidelines
- âœ… Focus on WHAT users need and WHY
- âŒ Avoid HOW to implement (no tech stack, APIs, code structure)
- ðŸ‘¥ Written for business stakeholders, not developers

---

## Clarifications

### Session 2025-10-17
- Q: When the embedding API service is unavailable or times out during document processing, what should happen to the document? â†’ A: Mark document as "completed" but flag embeddings as "pending" - document is usable but search won't include its tasks until embeddings succeed
- Q: When a document's task text is updated (edited by the system or re-extracted), should the existing embedding be replaced or preserved? â†’ A: Always regenerate embedding when task text changes (keep embeddings synchronized with current task content)
- Q: What observability signals (metrics or logs) are required to monitor embedding generation health and search performance? â†’ A: Minimal: Only log errors - no proactive metrics collection
- Q: How should the system handle rate limiting from the embedding API service? â†’ A: Queue requests and process them at a controlled rate to avoid hitting limits
- Q: When should failed embeddings (status: "failed") be retried? â†’ A: Retry only when user explicitly re-processes the document

---

## User Scenarios & Testing *(mandatory)*

### Primary User Story
When a user uploads a document containing tasks, the system automatically generates and stores semantic representations (embeddings) of each task during the initial processing. Later, when the user changes their outcome statement, the system can quickly find relevant tasks by comparing the outcome's semantic meaning against all stored task embeddings, returning results in under 500 milliseconds instead of 40+ seconds.

### Acceptance Scenarios

1. **Given** a document with 20 tasks is uploaded, **When** the document finishes processing, **Then** the system has generated and stored 20 task embeddings for future semantic searches

2. **Given** task embeddings are stored from 50 documents (200 total tasks), **When** a user searches for tasks semantically similar to "increase monthly revenue", **Then** the system returns the top 20 most relevant tasks within 500 milliseconds

3. **Given** task embeddings exist for a document, **When** that document is deleted, **Then** all associated task embeddings are also removed from storage

4. **Given** a user changes their outcome statement, **When** the system performs semantic search, **Then** results include similarity scores indicating how closely each task matches the outcome

5. **Given** 10,000 tasks with stored embeddings exist, **When** performing a semantic search, **Then** search completes in under 500ms (95th percentile) and returns results ranked by similarity

### Edge Cases
- What happens when a document contains 0 tasks?
  - System should skip embedding generation gracefully
- What happens when embedding generation fails for a single task?
  - System should log error, mark embedding as "failed", and continue processing remaining tasks
- What happens when the same document is uploaded twice?
  - System should use existing content hash to avoid duplicate embedding generation
- What happens when similarity search returns no results above threshold?
  - System should return empty results with appropriate message
- What happens during concurrent document uploads?
  - System should handle parallel embedding generation without conflicts using a shared request queue
- What happens when embedding API is unavailable during document processing?
  - Document marked as "completed" with embeddings status "pending" - tasks excluded from search until embeddings succeed
- What happens when embedding API rate limits are reached?
  - System queues requests and processes them at a controlled rate to avoid hitting limits
- What happens to failed embeddings?
  - Failed embeddings are NOT automatically retried - user must explicitly re-process the document to retry

---

## Requirements *(mandatory)*

### Functional Requirements

**Core Embedding Generation:**
- **FR-001**: System MUST automatically generate semantic embeddings for each extracted task during document processing
- **FR-002**: System MUST store task embeddings with associated metadata (task text, document reference, creation timestamp)
- **FR-003**: System MUST regenerate embeddings when task text changes to keep embeddings synchronized with current task content
- **FR-004**: System MUST support embedding regeneration when a document is explicitly re-processed by the user
- **FR-005**: Embedding generation MUST NOT block the user interface (runs asynchronously during document processing)
- **FR-024**: When embedding API is unavailable or times out, system MUST mark document as "completed" with embeddings flagged as "pending" - document remains usable but tasks excluded from search results until embeddings succeed
- **FR-025**: System MUST track embedding status per task (completed/pending/failed) to enable partial availability
- **FR-029**: System MUST queue embedding requests and process them at a controlled rate to prevent hitting embedding API rate limits
- **FR-030**: System MUST handle concurrent document uploads by managing a shared embedding request queue
- **FR-031**: Failed embeddings MUST NOT be automatically retried - retry only occurs when user explicitly re-processes the document

**Vector Search Capability:**
- **FR-006**: Users MUST be able to perform semantic searches to find tasks similar to a query text
- **FR-007**: System MUST return search results ranked by semantic similarity score (0.0 to 1.0 scale)
- **FR-008**: System MUST support configurable similarity threshold (default: 0.7 minimum)
- **FR-009**: System MUST support configurable result limit (default: 20 tasks)
- **FR-010**: Search results MUST include task text, similarity score, and source document reference

**Data Management:**
- **FR-011**: System MUST automatically delete task embeddings when the parent document is deleted
- **FR-012**: System MUST maintain referential integrity between embeddings and documents
- **FR-013**: System MUST support querying embeddings by document ID
- **FR-014**: System MUST support querying embeddings by task ID (unique hash)

**Performance Requirements:**
- **FR-015**: Semantic search MUST complete in under 500 milliseconds (95th percentile)
- **FR-016**: Embedding generation during document processing MUST add less than 2 seconds to total processing time
- **FR-017**: System MUST handle at least 10,000 stored task embeddings without performance degradation

**Quality Requirements:**
- **FR-018**: Top 20 search results MUST have similarity scores above 0.7 threshold
- **FR-019**: Manual review of search results MUST show at least 80% relevance accuracy
- **FR-020**: System MUST use consistent embedding model for all tasks (to ensure comparable similarity scores)

**Cost Constraints:**
- **FR-021**: Embedding generation MUST be one-time cost per task (not regenerated on every search)
- **FR-022**: System MUST minimize API calls by batching embedding generation where possible
- **FR-023**: Storage cost per task embedding MUST be negligible (under 10KB per task)

**Observability Requirements:**
- **FR-026**: System MUST log all errors during embedding generation (API failures, timeouts, validation errors)
- **FR-027**: System MUST log all errors during similarity searches (query failures, index unavailability)
- **FR-028**: Error logs MUST include context (document ID, task ID, timestamp, error message) for debugging

### Key Entities *(include if feature involves data)*

- **Task Embedding**: A semantic vector representation (1536 dimensions) of a task's text content, enabling similarity comparisons. Each embedding is associated with:
  - Task text (the original action/task description)
  - Task ID (unique identifier derived from task text and document)
  - Document ID (reference to source document)
  - Creation timestamp (created_at)
  - Last update timestamp (updated_at)

- **Similarity Search Result**: The output of a semantic search query containing:
  - Matched task text
  - Similarity score (float between 0.0 and 1.0)
  - Document reference
  - Task metadata

- **Vector Index**: An optimized data structure for fast similarity searches across thousands of embeddings. Supports:
  - Cosine similarity distance operations
  - Threshold-based filtering
  - Top-K result retrieval

---

## Review & Acceptance Checklist
*GATE: Automated checks run during main() execution*

### Content Quality
- [x] No implementation details (languages, frameworks, APIs)
- [x] Focused on user value and business needs
- [x] Written for non-technical stakeholders
- [x] All mandatory sections completed

### Requirement Completeness
- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Requirements are testable and unambiguous
- [x] Success criteria are measurable
- [x] Scope is clearly bounded
- [x] Dependencies and assumptions identified

---

## Execution Status
*Updated by main() during processing*

- [x] User description parsed
- [x] Key concepts extracted
- [x] Ambiguities marked
- [x] User scenarios defined
- [x] Requirements generated
- [x] Entities identified
- [x] Review checklist passed

---

## Dependencies & Assumptions

**Dependencies:**
- Existing document processing pipeline (upload, conversion, extraction)
- Existing task extraction from documents
- External embedding API service (for generating vector representations)

**Assumptions:**
- Task text content is already being extracted from documents
- Document content hashes are already being computed for deduplication
- System has access to embedding generation API with <200ms latency per individual embedding request. Batch processing of 50 tasks should complete within 2 seconds total (see FR-016)
- Users have fewer than 10,000 total tasks in the system (P0 scale target)

**Out of Scope (Phase 1):**
- Full-text keyword search (semantic search only)
- Multi-modal embeddings (images, PDFs - text only)
- Custom embedding model training or fine-tuning
- Embedding compression or quantization
- Hybrid search combining semantic + keyword matching
- Versioned embeddings (keeping historical embedding snapshots)
- Automatic embedding regeneration when task text changes (FR-003, FR-004 deferred to Phase 2)
