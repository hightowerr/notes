# Data Model: Document Reprocessing

**Feature**: Document Reprocessing
**Date**: 2025-11-05

## Overview

Document reprocessing reuses the existing database schema. No new tables or columns required. This document describes state transitions and data flow during reprocessing.

## Existing Schema (Reused)

### uploaded_files

Primary table tracking document metadata and processing status.

**Relevant Columns**:
```sql
id                UUID PRIMARY KEY
name              TEXT NOT NULL
source            TEXT NOT NULL  -- 'upload' | 'google_drive' | 'text_input'
external_id       TEXT           -- Google Drive file ID (NULL for uploads)
storage_path      TEXT           -- Supabase Storage path
status            TEXT NOT NULL  -- 'pending' | 'processing' | 'completed' | 'failed' | 'review_required'
uploaded_at       TIMESTAMP NOT NULL
processed_at      TIMESTAMP
queue_position    INTEGER        -- NULL when not in queue
```

**Reprocessing Changes**:
- `status`: Reset to 'pending' (from any terminal state)
- `processed_at`: Updated when reprocessing completes
- `queue_position`: Set by processing queue
- `uploaded_at`: **Preserved** (original upload timestamp)
- `external_id`: **Preserved** (Drive file ID)
- `storage_path`: **Preserved** for uploads, **Updated** for Drive (latest download)

### processed_documents

Stores AI-generated analysis results.

**Relevant Columns**:
```sql
id                UUID PRIMARY KEY
file_id           UUID REFERENCES uploaded_files(id) ON DELETE CASCADE
summary_json      JSONB NOT NULL  -- Topics, decisions, actions, LNO tasks
confidence_score  FLOAT
markdown_content  TEXT
created_at        TIMESTAMP NOT NULL
```

**Reprocessing Behavior**:
- **DELETE** old record when reprocessing starts
- **INSERT** new record when processing pipeline completes
- CASCADE deletion automatically removes:
  - `task_embeddings` records (via file_id FK)
  - `task_relationships` records (via file_id FK)

### task_embeddings

Vector embeddings for semantic search.

**Relevant Columns**:
```sql
id                UUID PRIMARY KEY
file_id           UUID REFERENCES uploaded_files(id) ON DELETE CASCADE
task_text         TEXT NOT NULL
embedding         VECTOR(1536)
status            TEXT  -- 'pending' | 'completed' | 'failed'
```

**Reprocessing Behavior**:
- Automatically deleted via CASCADE when `processed_documents` is deleted
- Regenerated by embedding pipeline after new processing completes

### task_relationships

Task dependencies detected by AI.

**Relevant Columns**:
```sql
id                UUID PRIMARY KEY
file_id           UUID REFERENCES uploaded_files(id) ON DELETE CASCADE
task_id_from      UUID
task_id_to        UUID
relationship_type TEXT  -- 'prerequisite' | 'blocking' | 'related'
```

**Reprocessing Behavior**:
- Automatically deleted via CASCADE when `processed_documents` is deleted
- Regenerated by dependency detection if relationships still exist

### processing_logs

Audit trail for all processing operations.

**Relevant Columns**:
```sql
id                UUID PRIMARY KEY
file_id           UUID REFERENCES uploaded_files(id)
operation         TEXT  -- 'upload' | 'process' | 'reprocess' | 'delete'
status            TEXT  -- 'started' | 'completed' | 'failed'
error_message     TEXT
metadata          JSONB
created_at        TIMESTAMP NOT NULL
```

**Reprocessing Behavior**:
- **INSERT** new log entry with `operation = 'reprocess'` when reprocessing starts
- **INSERT** completion log when reprocessing finishes (success or failure)
- Old logs preserved for audit trail

## State Transitions

### Happy Path: Manual Upload Reprocessing

```
1. Initial State:
   uploaded_files:
     id: abc-123
     status: 'completed'
     source: 'upload'
     storage_path: 'notes/hash123.pdf'

   processed_documents:
     file_id: abc-123
     summary_json: { old summary }
     confidence_score: 0.65

   task_embeddings:
     [10 embeddings for file abc-123]

2. User Clicks "Reprocess":
   POST /api/documents/abc-123/reprocess

3. Reprocess Endpoint:
   - Validate: source != 'text_input' ✓
   - Validate: status != 'processing' ✓
   - Delete processed_documents (CASCADE removes embeddings/relationships)
   - Update uploaded_files: status = 'pending'
   - Trigger: POST /api/process with fileId

4. Processing Pipeline (Existing):
   - Queue adds document (queue_position assigned)
   - Convert PDF to Markdown (using storage_path)
   - Extract AI summary (new confidence score)
   - Generate embeddings
   - Insert new processed_documents record

5. Final State:
   uploaded_files:
     id: abc-123
     status: 'completed'  (or 'review_required' if low confidence)
     processed_at: 2025-11-05 14:30:00  (updated)

   processed_documents:
     file_id: abc-123
     summary_json: { new improved summary }
     confidence_score: 0.85
     created_at: 2025-11-05 14:30:00  (new record)

   task_embeddings:
     [12 new embeddings for file abc-123]

   processing_logs:
     operation: 'reprocess'
     status: 'completed'
```

### Happy Path: Google Drive Reprocessing

```
1. Initial State:
   uploaded_files:
     id: def-456
     source: 'google_drive'
     external_id: '1ABC...XYZ'
     storage_path: 'notes/drive-def456.pdf'

2. User Clicks "Reprocess":
   POST /api/documents/def-456/reprocess

3. Reprocess Endpoint:
   - Validate source != 'text_input' ✓
   - Detect source == 'google_drive'
   - Download latest from Drive using external_id
   - Upload to storage (new storage_path or overwrite)
   - Delete old processed_documents
   - Reset status = 'pending'
   - Trigger POST /api/process

4. Processing Pipeline:
   - (Same as manual upload, uses latest downloaded file)

5. Final State:
   uploaded_files:
     storage_path: 'notes/drive-def456-v2.pdf'  (updated)
     status: 'completed'
```

### Error Path: Text Input (Not Allowed)

```
1. User Attempts Reprocess on Text Input Document:
   POST /api/documents/text-789/reprocess

2. Reprocess Endpoint:
   - Query uploaded_files where id = 'text-789'
   - Detect source = 'text_input'
   - Return 400: "Cannot reprocess text input documents - no file stored"

3. Frontend:
   - Display error toast
   - No database changes
```

### Error Path: Already Processing

```
1. Document Currently Processing:
   uploaded_files:
     id: ghi-101
     status: 'processing'

2. User Attempts Reprocess:
   POST /api/documents/ghi-101/reprocess

3. Reprocess Endpoint:
   - Detect status = 'processing'
   - Return 409: "Document is already being processed"

4. Frontend:
   - Display info toast
   - No database changes
```

### Error Path: Google Drive File Deleted

```
1. User Attempts Reprocess:
   POST /api/documents/jkl-202/reprocess

2. Reprocess Endpoint:
   - Detect source = 'google_drive'
   - Attempt download via Drive API
   - Drive API returns 404

3. Error Handling:
   - Log error to processing_logs (operation='reprocess', status='failed')
   - Return 404: "File no longer available in Google Drive"

4. Frontend:
   - Display error toast
   - Document remains in previous state (old data preserved)
```

### Error Path: Processing Fails

```
1. Reprocessing Triggered Successfully

2. Processing Pipeline Fails (e.g., AI timeout):
   - Old processed_documents already deleted
   - New processing fails before completion

3. Error Handling:
   - uploaded_files.status = 'failed'
   - No new processed_documents record created
   - User sees empty analysis (old data gone)

4. Recovery:
   - User can retry reprocessing
   - Or delete document and re-upload
```

**⚠️ CRITICAL**: To prevent data loss, consider implementing "soft delete" pattern:
- Option 1: Delete old data AFTER new processing succeeds
- Option 2: Mark old data as 'superseded' before deletion

**Recommendation**: Implement Option 1 (delete after success) in reprocess endpoint.

## Data Integrity Constraints

### CASCADE Deletion Verification

**Requirement**: When `processed_documents` is deleted, all related data must be cleaned up.

**Verification Query** (run in test environment):
```sql
-- Before reprocessing
SELECT
  (SELECT count(*) FROM processed_documents WHERE file_id = 'test-id') as docs,
  (SELECT count(*) FROM task_embeddings WHERE file_id = 'test-id') as embeddings,
  (SELECT count(*) FROM task_relationships WHERE file_id = 'test-id') as relationships;

-- Trigger reprocessing (deletes processed_documents)

-- After deletion, before new processing
SELECT
  (SELECT count(*) FROM processed_documents WHERE file_id = 'test-id') as docs,      -- Should be 0
  (SELECT count(*) FROM task_embeddings WHERE file_id = 'test-id') as embeddings,    -- Should be 0
  (SELECT count(*) FROM task_relationships WHERE file_id = 'test-id') as relationships; -- Should be 0
```

**Expected Results**: All counts = 0 after deletion.

### Google Drive Sync State Preservation

**Requirement**: Google Drive sync state must be maintained during reprocessing.

**Preserved Fields**:
- `external_id`: Drive file ID (used for future webhook notifications)
- `source`: 'google_drive' (identifies sync origin)
- `uploaded_at`: Original sync timestamp

**Verification**:
```sql
-- Before reprocessing
SELECT external_id, source, uploaded_at FROM uploaded_files WHERE id = 'drive-doc-id';

-- After reprocessing
SELECT external_id, source, uploaded_at FROM uploaded_files WHERE id = 'drive-doc-id';

-- Values should match (only status, processed_at change)
```

## Summary

**No new database entities required**. Reprocessing leverages existing schema with:
- CASCADE deletion for data cleanup
- Status transitions via existing states
- Processing logs for audit trail
- Metadata preservation for Drive sync

**Critical Design Decision**: Implement "delete after success" pattern to prevent data loss on processing failure.
