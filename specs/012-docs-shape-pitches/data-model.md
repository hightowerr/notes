# Data Model: Outcome-Driven Prioritization

**Feature**: Phase 14 - Evaluator-Optimizer Pattern
**Date**: 2025-11-18
**Status**: Complete

## Overview

This document defines the data structures for the unified prioritization system with hybrid evaluation loop. All schemas use Zod for validation and TypeScript for type safety.

---

## Core Entities

### 1. PrioritizationResult

Generated by the unified generator agent in a single pass.

```typescript
import { z } from 'zod';

export const prioritizationResultSchema = z.object({
  // Chain-of-thought reasoning (transparency requirement FR-010)
  thoughts: z.object({
    outcome_analysis: z.string().min(10).max(1000),
    filtering_rationale: z.string().min(10).max(1000),
    prioritization_strategy: z.string().min(10).max(1000),
    self_check_notes: z.string().min(10).max(1000),
  }),

  // Included tasks (passed filtering stage)
  included_tasks: z.array(z.object({
    task_id: z.string().uuid(),
    inclusion_reason: z.string().min(10).max(300),
    alignment_score: z.number().min(0).max(10), // 0-10 outcome alignment strength
  })).min(1).max(500),

  // Excluded tasks (failed filtering stage - FR-002, FR-011)
  excluded_tasks: z.array(z.object({
    task_id: z.string().uuid(),
    exclusion_reason: z.string().min(10).max(300),
    alignment_score: z.number().min(0).max(10), // Still scored for transparency
  })).max(500),

  // Final ordering (FR-004)
  ordered_task_ids: z.array(z.string().uuid()).min(1).max(500),

  // Per-task scoring details (FR-004, FR-010)
  per_task_scores: z.record(z.string().uuid(), z.object({
    impact: z.number().min(0).max(10), // Business value score
    effort: z.number().min(0.5).max(160), // Hours estimate
    confidence: z.number().min(0).max(1), // Scoring confidence
    reasoning: z.string().min(10).max(500), // Why this score?
    dependencies: z.array(z.string().uuid()).optional(), // Prerequisite task IDs
  })),

  // Overall confidence in this prioritization (FR-005)
  confidence: z.number().min(0).max(1),

  // Critical path explanation (FR-010)
  critical_path_reasoning: z.string().min(10).max(1000),

  // Self-corrections made during inline evaluation (FR-005)
  corrections_made: z.string().max(500).optional(),
});

export type PrioritizationResult = z.infer<typeof prioritizationResultSchema>;
```

**File Location**: `lib/schemas/prioritizationResultSchema.ts`

**Usage**: Returned by `prioritizationGenerator` agent

**Validation Rules**:
- At least 1 included task (cannot exclude everything)
- Max 500 tasks total (performance constraint)
- Alignment scores 0-10 (even for excluded tasks - transparency)
- Confidence 0-1 (self-assessment quality)

---

### 2. EvaluationResult

Generated by the evaluator agent when quality loop triggers.

```typescript
import { z } from 'zod';

export const evaluationResultSchema = z.object({
  // Overall evaluation decision (FR-007)
  status: z.enum(['PASS', 'NEEDS_IMPROVEMENT', 'FAIL']),

  // Specific, actionable feedback (FR-007)
  feedback: z.string().min(20).max(2000),

  // Detailed criteria scores
  criteria_scores: z.object({
    outcome_alignment: z.object({
      score: z.number().min(0).max(10),
      notes: z.string().max(500).optional(),
    }),
    strategic_coherence: z.object({
      score: z.number().min(0).max(10),
      notes: z.string().max(500).optional(),
    }),
    reflection_integration: z.object({
      score: z.number().min(0).max(10),
      notes: z.string().max(500).optional(),
    }),
    continuity: z.object({
      score: z.number().min(0).max(10),
      notes: z.string().max(500).optional(),
    }),
  }),

  // Evaluation metadata
  evaluation_duration_ms: z.number().int().min(0),
  evaluator_model: z.string(), // e.g., "gpt-4o-mini"
});

export type EvaluationResult = z.infer<typeof evaluationResultSchema>;
```

**File Location**: `lib/schemas/evaluationResultSchema.ts`

**Usage**: Returned by `prioritizationEvaluator` agent

**Decision Logic**:
- **PASS**: All criteria scores ≥7, proceed with prioritization
- **NEEDS_IMPROVEMENT**: Some scores <7, provide feedback for refinement
- **FAIL**: Critical scores <5, major rework needed

---

### 3. HybridLoopMetadata

Tracks evaluation loop execution and chain-of-thought iterations.

```typescript
import { z } from 'zod';

export const chainOfThoughtStepSchema = z.object({
  iteration: z.number().int().min(1).max(3), // Max 3 iterations (FR-008)
  confidence: z.number().min(0).max(1), // Confidence at this iteration
  corrections: z.string().max(500), // What was fixed
  evaluator_feedback: z.string().max(1000).optional(), // Only if evaluation triggered
  timestamp: z.string().datetime(),
});

export const hybridLoopMetadataSchema = z.object({
  // Loop execution stats
  iterations: z.number().int().min(1).max(3),
  duration_ms: z.number().int().min(0),
  evaluation_triggered: z.boolean(),

  // Chain-of-thought history (FR-012)
  chain_of_thought: z.array(chainOfThoughtStepSchema).min(1).max(3),

  // Final status
  converged: z.boolean(), // Did we reach PASS before max iterations?
  final_confidence: z.number().min(0).max(1),
});

export type HybridLoopMetadata = z.infer<typeof hybridLoopMetadataSchema>;
export type ChainOfThoughtStep = z.infer<typeof chainOfThoughtStepSchema>;
```

**File Location**: `lib/schemas/hybridLoopMetadataSchema.ts`

**Usage**: Stored in `agent_sessions.evaluation_metadata` JSONB column

**Retention**: 30 days (FR-023, clarification #4)

---

### 4. ExcludedTask

Subset of task data with exclusion reasoning (UI display).

```typescript
import { z } from 'zod';

export const excludedTaskSchema = z.object({
  task_id: z.string().uuid(),
  task_text: z.string().min(1).max(1000),
  exclusion_reason: z.string().min(10).max(300),
  alignment_score: z.number().min(0).max(10), // Transparency even when excluded
});

export type ExcludedTask = z.infer<typeof excludedTaskSchema>;
```

**File Location**: `lib/schemas/excludedTaskSchema.ts`

**Usage**: UI component `ExcludedTasksSection.tsx` (FR-011)

---

### 5. TaskScore

Per-task scoring details for display in reasoning modal.

```typescript
import { z } from 'zod';

export const taskScoreSchema = z.object({
  task_id: z.string().uuid(),
  impact: z.number().min(0).max(10), // 0-10 business value
  effort: z.number().min(0.5).max(160), // Hours estimate (0.5h minimum)
  confidence: z.number().min(0).max(1), // Scoring confidence
  reasoning: z.string().min(10).max(500), // Explanation text
  dependencies: z.array(z.string().uuid()).optional(), // Prerequisite task IDs
});

export type TaskScore = z.infer<typeof taskScoreSchema>;
```

**File Location**: `lib/schemas/taskScoreSchema.ts`

**Usage**: UI component `ScoreBreakdownModal.tsx` (displays when user clicks "[Why this score?]")

---

## Database Schema

### Table: `agent_sessions`

**Existing Columns** (preserved):
- `id` (UUID, primary key)
- `user_id` (UUID, foreign key to users)
- `outcome_id` (UUID, foreign key to user_outcomes)
- `status` (text: 'pending' | 'running' | 'completed' | 'failed')
- `prioritized_plan` (JSONB - keeps existing PrioritizedTaskPlan format)
- `execution_metadata` (JSONB)
- `created_at` (timestamp)
- `updated_at` (timestamp)

**New Columns** (FR-018):

```sql
-- Migration file: supabase/migrations/026_add_unified_prioritization_columns.sql

ALTER TABLE agent_sessions
  ADD COLUMN excluded_tasks JSONB,
  ADD COLUMN evaluation_metadata JSONB;

-- Comment for documentation
COMMENT ON COLUMN agent_sessions.excluded_tasks IS
  'Array of {task_id, task_text, exclusion_reason, alignment_score} - tasks filtered out during outcome alignment stage';

COMMENT ON COLUMN agent_sessions.evaluation_metadata IS
  'Hybrid loop metadata: {iterations, duration_ms, evaluation_triggered, chain_of_thought, converged, final_confidence}';
```

**Indexes** (performance optimization):

```sql
-- Index for querying recent sessions with excluded tasks
CREATE INDEX idx_agent_sessions_excluded_tasks_gin
  ON agent_sessions USING GIN (excluded_tasks)
  WHERE excluded_tasks IS NOT NULL;

-- Index for evaluation metadata queries
CREATE INDEX idx_agent_sessions_evaluation_metadata_gin
  ON agent_sessions USING GIN (evaluation_metadata)
  WHERE evaluation_metadata IS NOT NULL;

-- Index for cleanup job (30-day retention per FR-023)
CREATE INDEX idx_agent_sessions_created_at
  ON agent_sessions (created_at)
  WHERE evaluation_metadata IS NOT NULL;
```

---

### Table: `processing_logs`

**Existing Table** (used for override logging per FR-024)

**New Log Types**:

```sql
-- Override logging
INSERT INTO processing_logs (
  session_id,
  log_type,
  log_level,
  message,
  metadata
) VALUES (
  $1, -- session_id
  'user_override',
  'info',
  'User manually adjusted task prioritization',
  jsonb_build_object(
    'task_id', $2,
    'override_type', $3, -- 'move_to_excluded' | 'move_to_included' | 'score_adjustment'
    'original_decision', $4, -- 'included' | 'excluded'
    'user_decision', $5, -- 'included' | 'excluded'
    'timestamp', now()
  )
);
```

---

## Type Relationships

```
┌────────────────────────────────────────────────────────────┐
│                    Agent Workflow                          │
└────────────────────────────────────────────────────────────┘
                           │
                           ↓
    ┌──────────────────────────────────────────────┐
    │  prioritizationGenerator (GPT-4o)            │
    │  Returns: PrioritizationResult               │
    │    - thoughts                                 │
    │    - included_tasks[]                         │
    │    - excluded_tasks[]                         │
    │    - ordered_task_ids[]                       │
    │    - per_task_scores{}                        │
    │    - confidence                               │
    └──────────────────────────────────────────────┘
                           │
                           ↓
              ┌────────────────────┐
              │  needsEvaluation?  │
              │  (confidence < 0.7)│
              └────────────────────┘
                           │
                ┌──────────┴──────────┐
                │                     │
               YES                    NO
                │                     │
                ↓                     ↓
    ┌──────────────────────┐   ┌─────────────┐
    │ prioritizationEvaluator│   │  DONE       │
    │ (GPT-4o-mini)          │   │  Fast Path  │
    │ Returns: EvaluationResult│ │  ~15s       │
    │   - status (PASS/FAIL) │   └─────────────┘
    │   - feedback           │
    │   - criteria_scores    │
    └──────────────────────┘
                │
                ↓
       ┌────────────────┐
       │  PASS?         │
       └────────────────┘
                │
         ┌──────┴──────┐
         │             │
        YES            NO
         │             │
         ↓             ↓
    ┌─────────┐  ┌──────────────────┐
    │  DONE   │  │  Refine (max 3x) │
    │  ~28s   │  │  Loop back       │
    └─────────┘  └──────────────────┘
                           │
                           ↓
                 ┌──────────────────┐
                 │  Best Effort     │
                 │  (if 3 fails)    │
                 └──────────────────┘
```

---

## Data Flow Example

### Scenario: User triggers prioritization with outcome "Increase credit payments by 20%"

**Input Context**:
```typescript
{
  outcome: {
    assembled_text: "Increase credit payment conversion by 20%",
    direction: "increase",
    metric_text: "credit payment conversion",
    // ...
  },
  reflections: [
    { text: "ignore wishlist related items", created_at: "2025-11-17T10:00:00Z" },
    { text: "focus on mobile users this week", created_at: "2025-11-18T09:00:00Z" }
  ],
  tasks: [
    { task_id: "task-001", task_text: "Implement Apple Pay V6 integration" },
    { task_id: "task-002", task_text: "Update API documentation" },
    { task_id: "task-003", task_text: "Add loading spinner to dashboard" },
    { task_id: "task-004", task_text: "Optimize checkout flow for mobile" },
    // ... 196 more tasks
  ]
}
```

**Step 1: Generator Agent (Fast Path - Confidence 0.87)**

```typescript
const prioritizationResult: PrioritizationResult = {
  thoughts: {
    outcome_analysis: "User wants to increase credit payments by 20%. Focus on payment features, checkout optimization, and conversion improvements.",
    filtering_rationale: "Excluded documentation, internal tooling, and wishlist items per reflection. Included payment integrations, checkout improvements, and mobile optimizations.",
    prioritization_strategy: "Prioritized high-impact payment features first, then mobile optimizations (per reflection 'focus on mobile'), then supporting infrastructure.",
    self_check_notes: "Reviewed exclusions - confirmed no high-impact payment tasks excluded. Top 10 forms clear critical path. Reflection 'ignore wishlist' correctly excluded 'Add wishlist export feature'."
  },

  included_tasks: [
    {
      task_id: "task-001",
      inclusion_reason: "Directly enables new credit payment option, high revenue impact",
      alignment_score: 9
    },
    {
      task_id: "task-004",
      inclusion_reason: "40% of users on mobile, improves conversion rate on primary platform",
      alignment_score: 8
    },
    // ... 45 more included tasks
  ],

  excluded_tasks: [
    {
      task_id: "task-002",
      exclusion_reason: "Documentation doesn't directly advance payment conversion metric",
      alignment_score: 2
    },
    {
      task_id: "task-003",
      exclusion_reason: "Minor UX polish, not on critical path for payment conversion",
      alignment_score: 3
    },
    // ... 151 more excluded tasks
  ],

  ordered_task_ids: ["task-001", "task-004", /* ... */],

  per_task_scores: {
    "task-001": {
      impact: 9,
      effort: 12,
      confidence: 0.85,
      reasoning: "Apple Pay integration directly adds new payment method. Effort estimate based on similar integrations (Stripe took 10h, Apple Pay likely 12h due to iOS-specific testing).",
      dependencies: []
    },
    "task-004": {
      impact: 7,
      effort: 16,
      confidence: 0.78,
      reasoning: "Mobile checkout optimization improves conversion for 40% of user base. Higher effort due to responsive design + testing across devices.",
      dependencies: ["task-001"] // After payment integration
    },
    // ...
  },

  confidence: 0.87, // HIGH - Skip evaluation loop
  critical_path_reasoning: "Top 10 tasks form logical progression: (1) Add payment methods, (2) Optimize checkout UX, (3) Remove friction points, (4) Test and deploy. Estimated 8-12 week timeline at 20h/week capacity.",
  corrections_made: "Initially included 'Refactor payment service' but moved to excluded after self-check - refactoring doesn't directly advance metric, defer to Phase 16."
};
```

**Step 2: Hybrid Loop Decision**

```typescript
function needsEvaluation(result: PrioritizationResult): boolean {
  if (result.confidence >= 0.85) return false; // ✅ 0.87 >= 0.85 → SKIP

  // Would trigger if:
  // - confidence < 0.7
  // - included_tasks.length < 10
  // - corrections_made.length > 100
  // - >30% tasks moved >5 positions

  return false; // FAST PATH
}
```

**Step 3: Store to Database**

```sql
UPDATE agent_sessions
SET
  status = 'completed',
  prioritized_plan = $1, -- Standard PrioritizedTaskPlan format
  excluded_tasks = $2, -- New JSONB column
  evaluation_metadata = $3, -- New JSONB column
  updated_at = now()
WHERE id = $4;
```

```typescript
// $2: excluded_tasks
[
  {
    "task_id": "task-002",
    "task_text": "Update API documentation",
    "exclusion_reason": "Documentation doesn't directly advance payment conversion metric",
    "alignment_score": 2
  },
  // ... 152 more
]

// $3: evaluation_metadata
{
  "iterations": 1,
  "duration_ms": 15234,
  "evaluation_triggered": false,
  "chain_of_thought": [
    {
      "iteration": 1,
      "confidence": 0.87,
      "corrections": "Initially included 'Refactor payment service' but moved to excluded after self-check - refactoring doesn't directly advance metric, defer to Phase 16.",
      "timestamp": "2025-11-18T14:32:15Z"
    }
  ],
  "converged": true,
  "final_confidence": 0.87
}
```

---

## Migration Strategy

### Step 1: Add New Columns (Non-Breaking)

```sql
-- Migration 026: Add excluded_tasks and evaluation_metadata columns
ALTER TABLE agent_sessions
  ADD COLUMN excluded_tasks JSONB,
  ADD COLUMN evaluation_metadata JSONB;

-- Backfill existing sessions with empty metadata (optional)
UPDATE agent_sessions
SET
  excluded_tasks = '[]'::jsonb,
  evaluation_metadata = '{
    "iterations": 1,
    "duration_ms": 0,
    "evaluation_triggered": false,
    "chain_of_thought": [],
    "converged": true,
    "final_confidence": 0.5
  }'::jsonb
WHERE excluded_tasks IS NULL
  AND status = 'completed';
```

### Step 2: Feature Flag Rollout

```typescript
// lib/config/featureFlags.ts
export const USE_UNIFIED_PRIORITIZATION = process.env.NEXT_PUBLIC_USE_UNIFIED_PRIORITIZATION === 'true';
```

### Step 3: Dual-Write Period (1 week)

```typescript
// Write to both old and new systems for safety
if (USE_UNIFIED_PRIORITIZATION) {
  const result = await prioritizeWithHybridLoop(context);
  // Write to new columns
} else {
  const result = await buildAdjustedPlanFromReflections(context);
  // Write to old columns only
}
```

### Step 4: Full Migration (Week 2)

```typescript
// Remove old system after validation
// Mark reflectionBasedRanking.ts as @deprecated
```

---

## Validation Rules Summary

| Schema | Required Fields | Max Length | Min Values | Special Rules |
|--------|----------------|-----------|------------|---------------|
| PrioritizationResult | thoughts, included_tasks, ordered_task_ids, per_task_scores, confidence | 500 tasks | 1 included task | Confidence 0-1 |
| EvaluationResult | status, feedback, criteria_scores | 2000 char feedback | N/A | Status enum only |
| HybridLoopMetadata | iterations, duration_ms, evaluation_triggered, chain_of_thought | 3 iterations | 1 iteration | 30-day retention |
| ExcludedTask | task_id, task_text, exclusion_reason | 1000 char text | N/A | Alignment score 0-10 |
| TaskScore | task_id, impact, effort, confidence, reasoning | 500 char reasoning | 0.5h effort | Impact 0-10 |

---

**Version**: 1.0
**Last Updated**: 2025-11-18
**Author**: Phase 14 Implementation Planning
